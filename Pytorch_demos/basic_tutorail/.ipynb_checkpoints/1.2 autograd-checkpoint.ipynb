{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "介绍了pytorch中的自动求导功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 梯度下降法求极值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例：求函数y=6x^2的极值\n",
    "x = 10  # 初始值\n",
    "lr=0.01   # 学习率\n",
    "time_step = 0   # 初始时间\n",
    "time_list = []   # 步长列表\n",
    "x_list = []    # 自变量列表\n",
    "loss_list = []   # 损失函数值列表\n",
    "grad_list = []    # 梯度列表\n",
    "for epoch in range(3):    \n",
    "    for i in range(50):\n",
    "        loss = 3 * x * x    # 损失函数表达式\n",
    "        grad = 6 * x    # 梯度\n",
    "        time_list.append(time_step)\n",
    "        x_list.append(x)\n",
    "        loss_list.append(loss)\n",
    "        grad_list.append(grad)\n",
    "        x -= lr * grad    # 迭代公式\n",
    "        time_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(2,2)\n",
    "ax[0][0].plot(time_list, x_list)   # 迭代的变量\n",
    "ax[0][1].plot(time_list, loss_list)   # 损失的变化\n",
    "ax[1][0].plot(time_list, grad_list)   # 梯度的的变化\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pytorch中的自动求导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch的autograd模块实现了自动反向求导（DL的算法本质）的过程。\n",
    "从0.4起, Variable 正式合并入Tensor, Variable 本来实现的自动微分功能，Tensor就能支持。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在张量创建时，通过设置 requires_grad 标识为Ture来告诉Pytorch需要对该张量进行自动的求导，PyTorch回记录该张量的每一步操作历史并自动计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 示例1: 单变量的求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SumBackward0 object at 0x11891ac18>\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]]) tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 相当于求z=sum(w1+w2+...w8)，所以导数全部为0\n",
    "x = torch.rand(2,2,requires_grad=True)\n",
    "y = torch.rand(2,2,requires_grad=True)\n",
    "z = torch.sum(x+y)\n",
    "z.backward()\n",
    "print(z.grad_fn)\n",
    "print(x.grad, y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SumBackward0 object at 0x11891ae10>\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]]) None\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2,requires_grad=True)\n",
    "y = torch.rand(2,2)   # 默认requires_grad=False\n",
    "z = torch.sum(x+y)\n",
    "z.backward()\n",
    "print(z.grad_fn)\n",
    "print(x.grad, y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 示例2：多变量的求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9., 18.],\n",
      "        [ 9., 18.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1.0,2.0],[3.0,4.0]],requires_grad=True)\n",
    "y = torch.tensor([[2.0,3.0,4.0], [5.0,6.0,7.0]])\n",
    "z = torch.mm(x,y)\n",
    "z.backward(torch.ones_like(y))   # 必须传入一个和系数张量（非求导参数张量）相同shape的tensor，\n",
    "print(x.grad)   # 返回值为和x相同shape的张量，其中各元素为z对x各元素的梯度与y的线性和"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 示例3：梯度的自动累加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2,requires_grad=True)\n",
    "y = torch.rand(2,2,requires_grad=True)\n",
    "z = torch.sum(x+y)\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "z.backward()    # 若不对梯度进行清零，则在叶子节点上的梯度值会自动累加\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2,requires_grad=True)\n",
    "y = torch.rand(2,2,requires_grad=True)\n",
    "z = torch.sum(x+y)\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "x.grad.zero_()    # 若对梯度进行清零，则会对叶子节点上的梯度值进行重新计算\n",
    "z.backward()    \n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 示例4：求雅可比矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backward默认只对标量进行反向传递，如果需要求向量的导数，必须传入与系数阵同shape的标量作为参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.,  2.],\n",
      "        [ 4., 96.]])\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "x = torch.tensor([[2.0, 4.0]], requires_grad=True)   \n",
    "y = torch.zeros(1, 2)\n",
    "y[0,0] = x[0, 0] ** 2 + x[0, 1]\n",
    "y[0,1] = x[0, 1] ** 3 + 2 * x[0, 0]\n",
    "z = 2 * y\n",
    "z.backward(torch.FloatTensor([[1,0]]),retain_graph=True)\n",
    "jaccob1 = copy.deepcopy(x.grad)\n",
    "x.grad.zero_()\n",
    "z.backward(torch.FloatTensor([[0,1]]))\n",
    "jaccob2 = x.grad\n",
    "print(torch.cat((jaccob1, jaccob2), dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 示例5：多次反向传播需要申明retain_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 如果retain_graph=true,就会每次运行时重新生成图。也就是说，每次 backward() 时，默认会把整个计算图free掉。一般情况下是每次迭代，只需一次 forward() 和一次 backward() , 前向运算forward() 和反向传播backward()是成对存在的，一般一次backward()也是够用的。但是不排除，由于自定义loss等的复杂性，需要一次forward()，多个不同loss的backward()来累积同一个网络的grad来更新参数。于是，若在当前backward()后，不执行forward() 而可以执行另一个backward()，需要在当前backward()时，指定保留计算图，即backward(retain_graph)。\n",
    "2. 实测发现对于只有两层的聚合计算（如内置的mean、sum函数）无须显示声明retain_graph=True。而在其它情况下（比如输出非聚合计算，layer大于2），必须显示声明。具体原因未知。\n",
    "3. retain_graph的意义在于backward后重新保留图，否则无法forward，更无法第二次backward\n",
    "4. 设置retarin_graph=True,等效于再重新显式写一遍forward过程，之后再backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.,  2.],\n",
      "        [ 4., 96.]])\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "x = torch.tensor([[2.0, 4.0]], requires_grad=True)   \n",
    "y = torch.zeros(1, 2)\n",
    "y[0,0] = x[0, 0] ** 2 + x[0, 1]\n",
    "y[0,1] = x[0, 1] ** 3 + 2 * x[0, 0]\n",
    "z = 2 * y\n",
    "z.backward(torch.FloatTensor([[1,0]]),retain_graph=True)\n",
    "jaccob1 = copy.deepcopy(x.grad)\n",
    "x.grad.zero_()\n",
    "z.backward(torch.FloatTensor([[0,1]]))\n",
    "jaccob2 = x.grad\n",
    "print(torch.cat((jaccob1, jaccob2), dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 示例6：高阶导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一阶导数：(tensor([8.], grad_fn=<MulBackward0>),)\n",
      "二阶导数：(tensor([2.]),)\n"
     ]
    }
   ],
   "source": [
    "# 无法通过backward的自动求导实现\n",
    "x = torch.tensor([4.0], requires_grad=True)\n",
    "y = x**2\n",
    "grad_x = torch.autograd.grad(y, x, create_graph=True)   # 保留中间图，以供下一步的求导\n",
    "print(\"一阶导数：{}\".format(grad_x)) \n",
    "grad2_x = torch.autograd.grad(grad_x[0],x)\n",
    "print(\"二阶导数：{}\".format(grad2_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 示例7：禁止求导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用with torch.no_grad()禁止已经设置requires_grad=True的向量进行自动求导，这个方法在测试集测试准确率的时候回经常用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1,2,requires_grad=True)\n",
    "y = torch.rand(1,2)\n",
    "z = torch.mul(x, y)\n",
    "k = torch.sum(z)\n",
    "with torch.no_grad():\n",
    "    print(x.requires_grad)\n",
    "    print(z.requires_grad)\n",
    "    print((x*z+z).requires_grad)     # 只对在上下文管理中定义的图节点梯度进行禁止，而对外部的没用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
