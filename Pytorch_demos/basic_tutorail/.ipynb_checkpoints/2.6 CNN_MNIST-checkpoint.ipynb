{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例为利用pytorch中的CNN进行MNIST字体识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)\n",
    "\n",
    "# 超参数\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001   # 学习率\n",
    "DOWNLOAD_MNIST = False\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   # 选择CPU或GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9863168/9912422 [02:03<00:01, 25314.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [02:20, 25314.80it/s]                             \n",
      "  0%|          | 0/28881 [00:48<?, ?it/s]\u001b[A\n",
      " 57%|█████▋    | 16384/28881 [00:49<00:00, 32189.45it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1648877 [00:04<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 16384/1648877 [00:05<00:50, 32404.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 40960/1648877 [00:05<00:42, 37608.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 98304/1648877 [00:06<00:33, 46967.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 163840/1648877 [00:06<00:25, 57989.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 212992/1648877 [00:07<00:21, 65760.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 245760/1648877 [00:07<00:19, 70692.82it/s]\u001b[A\u001b[A\n",
      "32768it [01:06, 32189.45it/s]                           \u001b[A\n",
      "\n",
      " 18%|█▊        | 303104/1648877 [00:26<00:19, 70692.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 311296/1648877 [02:40<15:46, 1413.39it/s] \u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 401408/1648877 [02:40<10:19, 2012.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 450560/1648877 [02:41<07:00, 2851.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 491520/1648877 [02:41<04:48, 4018.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 499712/1648877 [02:41<03:37, 5280.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 548864/1648877 [02:42<02:29, 7370.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 581632/1648877 [02:42<01:45, 10124.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 622592/1648877 [02:43<01:14, 13849.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 630784/1648877 [02:43<01:07, 14983.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 679936/1648877 [02:44<00:47, 20224.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 704512/1648877 [02:45<00:42, 22011.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 729088/1648877 [02:45<00:34, 26683.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 753664/1648877 [02:45<00:28, 31366.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 778240/1648877 [02:46<00:23, 36472.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 802816/1648877 [02:46<00:20, 40526.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 811008/1648877 [02:47<00:27, 30982.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 843776/1648877 [02:47<00:20, 39656.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 868352/1648877 [02:47<00:16, 46173.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 892928/1648877 [02:48<00:14, 52839.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 917504/1648877 [02:48<00:12, 58911.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 950272/1648877 [02:48<00:10, 63968.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 966656/1648877 [02:49<00:11, 60340.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 999424/1648877 [02:49<00:09, 69394.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 1015808/1648877 [02:49<00:09, 63591.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 1040384/1648877 [02:50<00:08, 67793.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 1073152/1648877 [02:50<00:09, 62697.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 1105920/1648877 [02:50<00:07, 71555.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 1130496/1648877 [02:51<00:07, 73892.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 1146880/1648877 [02:51<00:07, 66240.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 1179648/1648877 [02:51<00:06, 74653.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 1204224/1648877 [02:52<00:05, 76149.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 1212416/1648877 [02:52<00:08, 49056.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 1245184/1648877 [02:52<00:06, 58502.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 1269760/1648877 [02:53<00:06, 62588.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 1294336/1648877 [02:54<00:08, 42703.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 1335296/1648877 [02:54<00:06, 51293.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 1359872/1648877 [02:55<00:05, 51052.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 1384448/1648877 [02:55<00:05, 49733.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 1409024/1648877 [02:56<00:04, 49250.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 1425408/1648877 [02:56<00:04, 46008.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 1449984/1648877 [02:57<00:05, 36081.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 1482752/1648877 [02:58<00:03, 41537.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 1490944/1648877 [02:58<00:05, 28087.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 1515520/1648877 [02:59<00:04, 32069.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 1531904/1648877 [02:59<00:03, 32047.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 1548288/1648877 [03:00<00:04, 24643.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 1572864/1648877 [03:01<00:02, 28839.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 1581056/1648877 [03:01<00:02, 25252.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 1597440/1648877 [03:01<00:01, 28144.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 1622016/1648877 [03:03<00:01, 23090.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 1638400/1648877 [03:04<00:00, 25196.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 1646592/1648877 [03:05<00:00, 11393.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4542 [00:02<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1654784it [03:16, 11393.27it/s]                             \u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# 下载训练数据\n",
    "import torchvision\n",
    "if not os.path.exists(\"./mnist/\") or not os.listdir('./mnist/'):\n",
    "    DOWNLOAD_MNIST = True\n",
    "    \n",
    "train_data = torchvision.datasets.MNIST(root='./mnist/', train=True, \n",
    "                                       transform=torchvision.transforms.ToTensor(), download=DOWNLOAD_MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "print(train_data.data.size())\n",
    "print(train_data.targets.size())\n",
    "plt.imshow(train_data.data[0].numpy(), cmap='gray')\n",
    "plt.title(\"数字{}\".format(train_data.targets[0].numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_x_batch, train_y_batch=next(iter(train_loader))\n",
    "print(train_x_batch.shape)\n",
    "print(train_y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 5, 7, 2, 2, 1, 1, 2, 5, 3, 3, 6, 8, 2, 2, 8, 1, 8, 6, 8, 3, 1, 3,\n",
       "        3, 1, 1, 5, 0, 2, 4, 1, 7, 0, 2, 6, 4, 7, 9, 9, 8, 7, 1, 7, 2, 0, 1, 2,\n",
       "        7, 3])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# 选取测试数据\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
    "test_data_n = torch.unsqueeze(test_data.data.float(), dim=1)\n",
    "test_label_n = test_data.targets\n",
    "test_n = Data.TensorDataset(test_data_n, test_label_n)\n",
    "test_loader = Data.DataLoader(dataset=test_n, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_x_batch, test_y_batch=next(iter(test_loader))\n",
    "print(test_x_batch.shape)\n",
    "print(test_y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 构建CNN网络\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1,28*28\n",
    "        self.conv1=torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5, padding=2),   # 1,28*28 ——> 16,28*28\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2)     # 16,28*28 ——> 16, 14*14\n",
    "        )\n",
    "        self.conv2=torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5, padding=2),   # 16,14*14 ——> 32,14*14\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2)     # 32,14*14 ——> 32,7*7\n",
    "        )\n",
    "        self.fc1 = torch.nn.Linear(32*7*7, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # forward传递的tensor相较于module中还包括了batch，即dim=0\n",
    "        x = x.view(x.size()[0], -1)   # 全连接层\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "net = Net().to(DEVICE)     # 移动到CPU或GPU\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器和损失函数\n",
    "criteria = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将训练的函数封装起来\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()    # 训练模式\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criteria(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx+1) % 30 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将测试的函数封装起来\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()     # 测试模式\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criteria(output, target)\n",
    "            pred = torch.max(output, dim=1)[1]\n",
    "            correct += torch.sum((pred==target))\n",
    "    correct = int(correct.numpy())\n",
    "    avg_loss = test_loss/len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        avg_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1450/60000 (2%)]\tLoss: 1.069325\n",
      "Train Epoch: 1 [2950/60000 (5%)]\tLoss: 0.469298\n",
      "Train Epoch: 1 [4450/60000 (7%)]\tLoss: 0.214996\n",
      "Train Epoch: 1 [5950/60000 (10%)]\tLoss: 0.519801\n",
      "Train Epoch: 1 [7450/60000 (12%)]\tLoss: 0.296257\n",
      "Train Epoch: 1 [8950/60000 (15%)]\tLoss: 0.273913\n",
      "Train Epoch: 1 [10450/60000 (17%)]\tLoss: 0.172666\n",
      "Train Epoch: 1 [11950/60000 (20%)]\tLoss: 0.295695\n",
      "Train Epoch: 1 [13450/60000 (22%)]\tLoss: 0.096153\n",
      "Train Epoch: 1 [14950/60000 (25%)]\tLoss: 0.093241\n",
      "Train Epoch: 1 [16450/60000 (27%)]\tLoss: 0.138215\n",
      "Train Epoch: 1 [17950/60000 (30%)]\tLoss: 0.106266\n",
      "Train Epoch: 1 [19450/60000 (32%)]\tLoss: 0.167032\n",
      "Train Epoch: 1 [20950/60000 (35%)]\tLoss: 0.198597\n",
      "Train Epoch: 1 [22450/60000 (37%)]\tLoss: 0.027744\n",
      "Train Epoch: 1 [23950/60000 (40%)]\tLoss: 0.051853\n",
      "Train Epoch: 1 [25450/60000 (42%)]\tLoss: 0.111037\n",
      "Train Epoch: 1 [26950/60000 (45%)]\tLoss: 0.228409\n",
      "Train Epoch: 1 [28450/60000 (47%)]\tLoss: 0.089811\n",
      "Train Epoch: 1 [29950/60000 (50%)]\tLoss: 0.076359\n",
      "Train Epoch: 1 [31450/60000 (52%)]\tLoss: 0.021294\n",
      "Train Epoch: 1 [32950/60000 (55%)]\tLoss: 0.063972\n",
      "Train Epoch: 1 [34450/60000 (57%)]\tLoss: 0.083367\n",
      "Train Epoch: 1 [35950/60000 (60%)]\tLoss: 0.027092\n",
      "Train Epoch: 1 [37450/60000 (62%)]\tLoss: 0.048198\n",
      "Train Epoch: 1 [38950/60000 (65%)]\tLoss: 0.097615\n",
      "Train Epoch: 1 [40450/60000 (67%)]\tLoss: 0.026545\n",
      "Train Epoch: 1 [41950/60000 (70%)]\tLoss: 0.064812\n",
      "Train Epoch: 1 [43450/60000 (72%)]\tLoss: 0.101679\n",
      "Train Epoch: 1 [44950/60000 (75%)]\tLoss: 0.058228\n",
      "Train Epoch: 1 [46450/60000 (77%)]\tLoss: 0.243368\n",
      "Train Epoch: 1 [47950/60000 (80%)]\tLoss: 0.113343\n",
      "Train Epoch: 1 [49450/60000 (82%)]\tLoss: 0.076028\n",
      "Train Epoch: 1 [50950/60000 (85%)]\tLoss: 0.084717\n",
      "Train Epoch: 1 [52450/60000 (87%)]\tLoss: 0.034861\n",
      "Train Epoch: 1 [53950/60000 (90%)]\tLoss: 0.084615\n",
      "Train Epoch: 1 [55450/60000 (92%)]\tLoss: 0.111997\n",
      "Train Epoch: 1 [56950/60000 (95%)]\tLoss: 0.146088\n",
      "Train Epoch: 1 [58450/60000 (97%)]\tLoss: 0.007504\n",
      "Train Epoch: 1 [59950/60000 (100%)]\tLoss: 0.104460\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 58849/60000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCH + 1):\n",
    "    train(net, DEVICE, train_loader, optimizer, epoch)\n",
    "    test(net, DEVICE, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
