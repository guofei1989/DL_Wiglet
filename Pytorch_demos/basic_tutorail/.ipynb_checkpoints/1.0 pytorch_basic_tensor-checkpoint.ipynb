{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "介绍了pytorch中张量tensor的初始化、数据类型转换、数据共享机制和常见的数学操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 张量初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3091, 0.7662, 0.8942],\n",
       "        [0.9112, 0.9844, 0.1651]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用[0,1]均匀分布随机初始化二维数组\n",
    "x = torch.rand(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 张量的形状\n",
    "print(x.shape)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0437,  0.7540, -0.1724],\n",
       "        [ 0.1647,  0.4260,  0.1639]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用[0,1]正态分布随机初始化二维数组\n",
    "y = torch.randn(2,3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 类似于numpy，可以生成值为0的张量，值为1的张量，或对角线张量\n",
    "torch.zeros(3,3)\n",
    "torch.ones(3,3)\n",
    "torch.eye(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 类似于numpy，可以生成按照线性分布或对数线性分布的张量\n",
    "torch.linspace(0,10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 2, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从0->n-1中随机的整数排列\n",
    "torch.randperm(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tensor的基本数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch定义了七种CPU tensor类型和八种GPU tensor类型\n",
    "其中基本数据类型有五种：\n",
    "32位浮点型：torch.FloatTensor。 (默认)\n",
    "64位整型：torch.LongTensor。\n",
    "32位整型：torch.IntTensor。\n",
    "16位整型：torch.ShortTensor。\n",
    "64位浮点型：torch.DoubleTensor。\n",
    "除以上数字类型外，还有 byte和chart型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 默认生成floattensor默认类型\n",
    "tensor = torch.tensor(3.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 长整数\n",
    "tensor.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3, dtype=torch.int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 整数\n",
    "tensor.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一个张量tensor可以从列表list构建\n",
    "torch.FloatTensor([[1,2], [3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一个空张量tensor可以通过规定其大小来构建：\n",
    "torch.IntTensor(2, 4).zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 张量的数据共享机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从列表生成的张量，会重新创建一个副本，没有数据共享\n",
    "listA = [[1,2], [3,4]]\n",
    "tensorA = torch.FloatTensor(listA)\n",
    "listA[0][0] = 100\n",
    "tensorA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100,   2],\n",
       "        [  3,   4]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从numpy生成的张量，会共用一个storage，从而实现数据共享\n",
    "arrayB = np.array([[1,2], [3,4]])\n",
    "tensorB = torch.from_numpy(arrayB)     # Numpy桥，实现数据类型转换\n",
    "arrayB[0,0] = 100\n",
    "tensorB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-100,    2],\n",
       "       [   3,    4]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 同样的若修改tensor，对应的numpy也会修改\n",
    "tensorB[0,0] = -100\n",
    "arrayB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 其他常用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 判断是否是tensor\n",
    "tensorD = torch.tensor(3.14)\n",
    "torch.is_tensor(tensorD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计张量中的元素个数\n",
    "tensorA.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换为numpy\n",
    "tensorA.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 张量的数学操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在pytorch中，数学操作.op会在一个新的tensor中计算结果，而.op_会在原地计算绝对值，并返回改变后的tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 元素操作，即对每个元素进行分别操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+, -, *, /均对应着元素级的运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 绝对值操作\n",
    "torch.abs(torch.FloatTensor([-1, -2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.3731, 10.4722, 10.1562,  8.9118])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逐元素求和操作torch.add(input, value, out=None)\n",
    "a = torch.randn(4)\n",
    "torch.add(a, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逐元素求和操作torch.add(input, other, out=None)\n",
    "a = torch.ones(2,2)\n",
    "b = torch.ones(2,2)\n",
    "torch.add(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.0272,   5.3425, -12.0566,  -2.4406])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逐元素求和操作torch.add(input, value, other, out=None)\n",
    "# other亦为一个张量，与input的shape要一样\n",
    "# 返回的结果shape同input，input+value*other的逐元素相加\n",
    "a = torch.randn(4)\n",
    "b = torch.randn(4)\n",
    "torch.add(a, 10, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0458, -0.0160,  0.0564, -0.0850])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逐元素相除torch.div(input, value, out=None)\n",
    "a = torch.randn(4)\n",
    "torch.div(a, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7443, 0.0962, 1.2753, 0.1943])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逐元素相除torch.div(input, other, out=None)\n",
    "a = torch.randn(4)\n",
    "b = torch.randn(4)\n",
    "torch.div(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  7.6040, -14.3957,   9.8995,   5.3044])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逐元素相乘torch.mul(input, value, out=None)\n",
    "a = torch.randn(4)\n",
    "torch.mul(a, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4658, -1.0494, -0.1179,  0.2468])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逐元素相除torch.div(input, other, out=None)\n",
    "a = torch.randn(4)\n",
    "b = torch.randn(4)\n",
    "torch.mul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4552, 0.2000, 0.2817],\n",
       "        [0.5000, 0.5000, 0.2000],\n",
       "        [0.5000, 0.5000, 0.2000]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 夹紧操作\n",
    "a = torch.rand(3,3)\n",
    "torch.clamp(a, min=0.2, max=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 地板\n",
    "torch.floor(torch.rand(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 天花板\n",
    "torch.ceil(torch.rand(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., -0., 0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 截断，取最近的整数\n",
    "a = torch.randn(4)\n",
    "torch.trunc(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7704e+00, 2.5027e-01, 2.7494e-01, 9.4109e-12])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指数运算torch.pow(input, exponent, out=None)，exponent可以为一个数，也可以为和input同size的张量，表示逐个元素求指数\n",
    "a = torch.randn(4)\n",
    "torch.pow(a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6638,  1.2887, -0.8049, -2.6916])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求倒数torch.reciprocal(input, out=None)\n",
    "a = torch.randn(4)\n",
    "torch.reciprocal(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid函数\n",
    "torch.sigmoid(input, out=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 约减操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4244,  0.3618,  0.0938, -0.2123,  0.1627,  0.0368])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 累进乘\n",
    "a = torch.randn(6)\n",
    "torch.cumprod(a,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3583)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所有元素的乘积 torch.prod(input) → float\n",
    "a = torch.randn(1, 3)\n",
    "torch.prod(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4996, 0.0054])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定维度上的元素乘积 torch.prod(input, dim, out=None) → Tensor\n",
    "a = torch.randn(2, 3)\n",
    "torch.prod(a,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1828,  0.6705, -0.3756, -0.7794, -0.8592, -2.1948])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 累进和\n",
    "a = torch.randn(6)\n",
    "torch.cumsum(a,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1436)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所有元素的和torch.sum(input) → float\n",
    "a = torch.randn(6)\n",
    "torch.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4298, -0.4332])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定维度上的元素和 torch.sum(input, dim, out=None) → Tensor\n",
    "a = torch.randn(2, 3)\n",
    "torch.sum(a,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5773)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输入张量的p-范数 torch.norm(input, p=2) → float\n",
    "a = torch.randn(1, 3)\n",
    "torch.norm(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7502)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 两个张量差的p-范数  torch.dist(input, other, p=2, out=None)，返回(input - other)的p范数\n",
    "x = torch.randn(4)\n",
    "y = torch.randn(4)\n",
    "torch.dist(x, y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3808)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所有元素的均值 torch.mean(input) → float\n",
    "a = torch.randn(2, 2)\n",
    "torch.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8770, -0.5026])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定dim上的张量元素均值 torch.mean(input, dim, out=None) → Tensor\n",
    "a = torch.randn(2, 2)\n",
    "torch.mean(a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0654, -0.8560, -0.2785,  0.6428]), tensor([3, 4, 0, 1]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定维度的中位数，默认dim为-1\n",
    "# torch.median(input, dim=-1, values=None, indices=None) -> (Tensor, LongTensor)\n",
    "a = torch.randn(4, 5)\n",
    "torch.median(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 2]), tensor([0, 0]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 众数 torch.mode(input, dim=-1, values=None, indices=None) -> (Tensor, LongTensor)\n",
    "a = torch.tensor([[0,0,1,1], [2,3,2,3]])\n",
    "torch.median(a, 1)   # 有多个众数时，只返回第一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有元素的标准差 torch.std(input) → float\n",
    "# 指定维度所有元素的标准差 torch.std(input, dim, out=None) → Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有元素的方差 torch.var(input) → float\n",
    "# 指定维度所有元素的标准差 torch.var(input, dim, out=None) → Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 矩阵运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7170, 0.9775],\n",
      "        [0.2589, 0.5155]])\n",
      "tensor([[1.2201, 1.5470],\n",
      "        [0.7962, 1.0185]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(2,2)\n",
    "print(torch.mul(x,x))   # 元素级相乘，同x * x\n",
    "print(torch.mm(x,x))    # 矩阵相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
