{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例为利用pytorch中的RNN进行MNIST字体识别\n",
    "即将图片的height视为timestep, width视为input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)\n",
    "\n",
    "# 超参数\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.01   # 学习率\n",
    "DOWNLOAD_MNIST = False\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   # 选择CPU或GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载训练数据\n",
    "import torchvision\n",
    "if not os.path.exists(\"./mnist/\") or not os.listdir('./mnist/'):\n",
    "    DOWNLOAD_MNIST = True\n",
    "    \n",
    "train_data = torchvision.datasets.MNIST(root='./mnist/', train=True, \n",
    "                                       transform=torchvision.transforms.ToTensor(), download=DOWNLOAD_MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "print(train_data.data.size())\n",
    "print(train_data.targets.size())\n",
    "plt.imshow(train_data.data[1].numpy(), cmap='gray')\n",
    "plt.title(\"数字{}\".format(train_data.targets[1].numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_x_batch, train_y_batch=next(iter(train_loader))\n",
    "print(train_x_batch.shape)\n",
    "print(train_y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 28, 28])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# 选取测试数据\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
    "test_data_n = test_data.data.float()/255.\n",
    "test_label_n = test_data.targets\n",
    "test_n = Data.TensorDataset(test_data_n, test_label_n)\n",
    "test_loader = Data.DataLoader(dataset=test_n, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_x_batch, test_y_batch=next(iter(test_loader))\n",
    "print(test_x_batch.shape)\n",
    "print(test_y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (lstm): LSTM(28, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 构建LSTM网络\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(num_layers=1, input_size=28, hidden_size=64, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(64, 10)\n",
    "    def forward(self, x):\n",
    "        # x shape:(batch, time_step, input_size)    where time_step=height, input=width\n",
    "        # r_out shape:(batch, time_step, hidden_size)   \n",
    "        # h_n shape:(n_layers, batch, hidden_size)\n",
    "        # c_n shape:(n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, c_n) = self.lstm(x, None)\n",
    "        output = self.fc(r_out[:,-1,:])     # 只取最后一个time_step的输出\n",
    "        return output\n",
    "\n",
    "net = Net().to(DEVICE)    # 移动到CPU或GPU\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器和损失函数\n",
    "criteria = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将训练的函数封装起来\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.view(-1, 28, 28)    # 取消通道维度\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)   \n",
    "        loss = criteria(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx+1) % 30 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将测试的函数封装起来\n",
    "def evaluate(model, device, test_loader):\n",
    "    model.eval()    # 测试模式\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.view(-1, 28, 28)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criteria(output, target)\n",
    "            pred = torch.max(output, dim=1)[1]\n",
    "            correct += torch.sum(pred==target)\n",
    "    correct = int(correct.numpy())\n",
    "    avg_loss = test_loss/len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        avg_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1450/60000 (2%)]\tLoss: 1.464822\n",
      "Train Epoch: 1 [2950/60000 (5%)]\tLoss: 1.654003\n",
      "Train Epoch: 1 [4450/60000 (7%)]\tLoss: 1.120378\n",
      "Train Epoch: 1 [5950/60000 (10%)]\tLoss: 0.831667\n",
      "Train Epoch: 1 [7450/60000 (12%)]\tLoss: 0.639030\n",
      "Train Epoch: 1 [8950/60000 (15%)]\tLoss: 0.527314\n",
      "Train Epoch: 1 [10450/60000 (17%)]\tLoss: 0.476858\n",
      "Train Epoch: 1 [11950/60000 (20%)]\tLoss: 0.449790\n",
      "Train Epoch: 1 [13450/60000 (22%)]\tLoss: 0.272321\n",
      "Train Epoch: 1 [14950/60000 (25%)]\tLoss: 0.580731\n",
      "Train Epoch: 1 [16450/60000 (27%)]\tLoss: 0.178241\n",
      "Train Epoch: 1 [17950/60000 (30%)]\tLoss: 0.377349\n",
      "Train Epoch: 1 [19450/60000 (32%)]\tLoss: 0.286074\n",
      "Train Epoch: 1 [20950/60000 (35%)]\tLoss: 0.539971\n",
      "Train Epoch: 1 [22450/60000 (37%)]\tLoss: 0.524976\n",
      "Train Epoch: 1 [23950/60000 (40%)]\tLoss: 0.075221\n",
      "Train Epoch: 1 [25450/60000 (42%)]\tLoss: 0.212871\n",
      "Train Epoch: 1 [26950/60000 (45%)]\tLoss: 0.209061\n",
      "Train Epoch: 1 [28450/60000 (47%)]\tLoss: 0.060563\n",
      "Train Epoch: 1 [29950/60000 (50%)]\tLoss: 0.118728\n",
      "Train Epoch: 1 [31450/60000 (52%)]\tLoss: 0.256477\n",
      "Train Epoch: 1 [32950/60000 (55%)]\tLoss: 0.290957\n",
      "Train Epoch: 1 [34450/60000 (57%)]\tLoss: 0.102151\n",
      "Train Epoch: 1 [35950/60000 (60%)]\tLoss: 0.238145\n",
      "Train Epoch: 1 [37450/60000 (62%)]\tLoss: 0.123955\n",
      "Train Epoch: 1 [38950/60000 (65%)]\tLoss: 0.094189\n",
      "Train Epoch: 1 [40450/60000 (67%)]\tLoss: 0.056856\n",
      "Train Epoch: 1 [41950/60000 (70%)]\tLoss: 0.054386\n",
      "Train Epoch: 1 [43450/60000 (72%)]\tLoss: 0.170076\n",
      "Train Epoch: 1 [44950/60000 (75%)]\tLoss: 0.248284\n",
      "Train Epoch: 1 [46450/60000 (77%)]\tLoss: 0.064268\n",
      "Train Epoch: 1 [47950/60000 (80%)]\tLoss: 0.034862\n",
      "Train Epoch: 1 [49450/60000 (82%)]\tLoss: 0.207105\n",
      "Train Epoch: 1 [50950/60000 (85%)]\tLoss: 0.022595\n",
      "Train Epoch: 1 [52450/60000 (87%)]\tLoss: 0.163217\n",
      "Train Epoch: 1 [53950/60000 (90%)]\tLoss: 0.220169\n",
      "Train Epoch: 1 [55450/60000 (92%)]\tLoss: 0.174030\n",
      "Train Epoch: 1 [56950/60000 (95%)]\tLoss: 0.047350\n",
      "Train Epoch: 1 [58450/60000 (97%)]\tLoss: 0.148215\n",
      "Train Epoch: 1 [59950/60000 (100%)]\tLoss: 0.155072\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 9573/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCH+1):\n",
    "    train(net, DEVICE, train_loader, optimizer, epoch)\n",
    "    evaluate(net, DEVICE, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
